{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 2:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
      "First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 3 Max Value: 219\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 3 Name: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nih4AGlP0ANCYogeAxv43XI8p802nQmEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a187c9b00>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 2\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "\n",
    "    return x/255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=(None, image_shape[0], image_shape[1], image_shape[2]),name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     print(n_classes)\n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes),name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.truncated_normal([*conv_ksize,int(x_tensor.get_shape()[3]),conv_num_outputs]))\n",
    "    biases = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    \n",
    "    layer = tf.nn.conv2d(x_tensor,weights,[1,*conv_strides,1],'VALID')\n",
    "    layer = tf.nn.bias_add(layer,biases)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.max_pool(layer,[1,*pool_ksize,1],[1,*pool_strides,1],'VALID')\n",
    "\n",
    "    # TODO: Implement Function\n",
    "    return layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn=tf.nn.relu)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    return tf.layers.dense(x_tensor,num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    filters_num = [64,128]\n",
    "    conv_ksize = [(8,8),(4,4)]\n",
    "    conv_strides = [(2,2),(1,1)]\n",
    "    pool_ksize = (3,3)\n",
    "    pool_strides = (2,2)\n",
    "    num_outputs = 10\n",
    "    \n",
    "    conv = conv2d_maxpool(x, filters_num[0], conv_ksize[0], conv_strides[0], pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(conv, filters_num[1], conv_ksize[1], conv_strides[1], pool_ksize, pool_strides)\n",
    "    conv = flatten(conv)\n",
    "    conv = fully_conn(conv, 512)\n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "    return output(conv,num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer,feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost,feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    validation_accuracy = session.run(accuracy,feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    \n",
    "    print('loss:{:>10} accuracy:{:>10}'.format(loss, validation_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss:18.100391387939453 accuracy:0.12837837636470795\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss:4.456549167633057 accuracy:0.1993243247270584\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss:2.391124725341797 accuracy:0.16554054617881775\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss:2.298495054244995 accuracy:0.18243242800235748\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss:2.253490447998047 accuracy:0.1756756752729416\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss:2.2123186588287354 accuracy:0.21621622145175934\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss:2.1743593215942383 accuracy:0.22297297418117523\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss:2.1813247203826904 accuracy:0.20270270109176636\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss:2.148775339126587 accuracy:0.21621622145175934\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss:2.1218438148498535 accuracy:0.24662162363529205\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss:2.0981128215789795 accuracy:0.25337839126586914\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss:2.0835046768188477 accuracy:0.2567567527294159\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss:2.0592188835144043 accuracy:0.23986487090587616\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss:2.0388591289520264 accuracy:0.2567567527294159\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss:2.0038280487060547 accuracy:0.25337839126586914\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss:1.9834529161453247 accuracy:0.26013514399528503\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss:1.9634959697723389 accuracy:0.27702704071998596\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss:1.934601068496704 accuracy:0.28378379344940186\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss:1.9241431951522827 accuracy:0.30405405163764954\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss:1.9311672449111938 accuracy:0.2871621549129486\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss:1.8958288431167603 accuracy:0.2939189076423645\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss:1.878348708152771 accuracy:0.2871621549129486\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss:1.8728405237197876 accuracy:0.29729729890823364\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss:1.8608243465423584 accuracy:0.31418919563293457\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss:1.8467601537704468 accuracy:0.3310810923576355\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss:1.8481123447418213 accuracy:0.3074324429035187\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss:1.8490902185440063 accuracy:0.31081080436706543\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss:1.815779209136963 accuracy:0.3310810923576355\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss:1.7907038927078247 accuracy:0.3445945978164673\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss:1.8004802465438843 accuracy:0.34121620655059814\n",
      "Epoch 31, CIFAR-10 Batch 1:  loss:1.783582091331482 accuracy:0.32770270109176636\n",
      "Epoch 32, CIFAR-10 Batch 1:  loss:1.7829304933547974 accuracy:0.36486485600471497\n",
      "Epoch 33, CIFAR-10 Batch 1:  loss:1.7582529783248901 accuracy:0.37837839126586914\n",
      "Epoch 34, CIFAR-10 Batch 1:  loss:1.7510731220245361 accuracy:     0.375\n",
      "Epoch 35, CIFAR-10 Batch 1:  loss:1.7457973957061768 accuracy:0.3817567527294159\n",
      "Epoch 36, CIFAR-10 Batch 1:  loss:1.7391151189804077 accuracy:     0.375\n",
      "Epoch 37, CIFAR-10 Batch 1:  loss:1.73346745967865 accuracy:0.3817567527294159\n",
      "Epoch 38, CIFAR-10 Batch 1:  loss:1.7089229822158813 accuracy:0.37837839126586914\n",
      "Epoch 39, CIFAR-10 Batch 1:  loss:1.7169567346572876 accuracy:0.4121621549129486\n",
      "Epoch 40, CIFAR-10 Batch 1:  loss:1.704864501953125 accuracy:0.3885135054588318\n",
      "Epoch 41, CIFAR-10 Batch 1:  loss:1.6970999240875244 accuracy:0.3918918967247009\n",
      "Epoch 42, CIFAR-10 Batch 1:  loss:1.678297519683838 accuracy:0.41554054617881775\n",
      "Epoch 43, CIFAR-10 Batch 1:  loss:1.6849639415740967 accuracy:0.40202704071998596\n",
      "Epoch 44, CIFAR-10 Batch 1:  loss:1.6581637859344482 accuracy:0.42905405163764954\n",
      "Epoch 45, CIFAR-10 Batch 1:  loss:1.6796765327453613 accuracy:0.38513514399528503\n",
      "Epoch 46, CIFAR-10 Batch 1:  loss:1.6604033708572388 accuracy:0.36486485600471497\n",
      "Epoch 47, CIFAR-10 Batch 1:  loss:1.6385059356689453 accuracy:0.4256756901741028\n",
      "Epoch 48, CIFAR-10 Batch 1:  loss:1.631983757019043 accuracy:0.4189189076423645\n",
      "Epoch 49, CIFAR-10 Batch 1:  loss:1.6172500848770142 accuracy:0.4121621549129486\n",
      "Epoch 50, CIFAR-10 Batch 1:  loss:1.6144627332687378 accuracy:0.4256756901741028\n",
      "Epoch 51, CIFAR-10 Batch 1:  loss:1.6146165132522583 accuracy:0.4121621549129486\n",
      "Epoch 52, CIFAR-10 Batch 1:  loss:1.600840449333191 accuracy:0.4324324429035187\n",
      "Epoch 53, CIFAR-10 Batch 1:  loss:1.6015492677688599 accuracy:0.45945945382118225\n",
      "Epoch 54, CIFAR-10 Batch 1:  loss:1.582615613937378 accuracy:0.4425675570964813\n",
      "Epoch 55, CIFAR-10 Batch 1:  loss:1.5708869695663452 accuracy:0.47297295928001404\n",
      "Epoch 56, CIFAR-10 Batch 1:  loss:1.5639852285385132 accuracy:0.4628378450870514\n",
      "Epoch 57, CIFAR-10 Batch 1:  loss:1.5507878065109253 accuracy:0.4797297418117523\n",
      "Epoch 58, CIFAR-10 Batch 1:  loss:1.5360093116760254 accuracy:0.4864864945411682\n",
      "Epoch 59, CIFAR-10 Batch 1:  loss:1.5337225198745728 accuracy:0.4831081032752991\n",
      "Epoch 60, CIFAR-10 Batch 1:  loss:1.5138611793518066 accuracy:0.46621620655059814\n",
      "Epoch 61, CIFAR-10 Batch 1:  loss:1.507686972618103 accuracy:0.4932432472705841\n",
      "Epoch 62, CIFAR-10 Batch 1:  loss:1.5098893642425537 accuracy:0.4932432472705841\n",
      "Epoch 63, CIFAR-10 Batch 1:  loss:1.5171177387237549 accuracy:0.47297295928001404\n",
      "Epoch 64, CIFAR-10 Batch 1:  loss:1.502388834953308 accuracy:0.4864864945411682\n",
      "Epoch 65, CIFAR-10 Batch 1:  loss:1.5144766569137573 accuracy:0.45945945382118225\n",
      "Epoch 66, CIFAR-10 Batch 1:  loss:1.502946138381958 accuracy:0.45270270109176636\n",
      "Epoch 67, CIFAR-10 Batch 1:  loss:1.4650280475616455 accuracy:0.4628378450870514\n",
      "Epoch 68, CIFAR-10 Batch 1:  loss:1.46747887134552 accuracy:0.4763513505458832\n",
      "Epoch 69, CIFAR-10 Batch 1:  loss:1.4474825859069824 accuracy:0.5101351141929626\n",
      "Epoch 70, CIFAR-10 Batch 1:  loss:1.444161057472229 accuracy:0.5168918967247009\n",
      "Epoch 71, CIFAR-10 Batch 1:  loss:1.4261553287506104 accuracy:0.5270270109176636\n",
      "Epoch 72, CIFAR-10 Batch 1:  loss:1.4233102798461914 accuracy:0.5033783912658691\n",
      "Epoch 73, CIFAR-10 Batch 1:  loss:1.4068886041641235 accuracy:0.5506756901741028\n",
      "Epoch 74, CIFAR-10 Batch 1:  loss:1.3915516138076782 accuracy:0.5540540814399719\n",
      "Epoch 75, CIFAR-10 Batch 1:  loss:1.3887848854064941 accuracy:0.5168918967247009\n",
      "Epoch 76, CIFAR-10 Batch 1:  loss:1.4015308618545532 accuracy:0.5304054021835327\n",
      "Epoch 77, CIFAR-10 Batch 1:  loss:1.4005764722824097 accuracy:0.5270270109176636\n",
      "Epoch 78, CIFAR-10 Batch 1:  loss:1.3771450519561768 accuracy:0.5574324131011963\n",
      "Epoch 79, CIFAR-10 Batch 1:  loss:1.3628785610198975 accuracy:0.5540540814399719\n",
      "Epoch 80, CIFAR-10 Batch 1:  loss:1.3631113767623901 accuracy:0.5506756901741028\n",
      "Epoch 81, CIFAR-10 Batch 1:  loss:1.3601806163787842 accuracy:0.5439189076423645\n",
      "Epoch 82, CIFAR-10 Batch 1:  loss:1.3327962160110474 accuracy:0.5540540814399719\n",
      "Epoch 83, CIFAR-10 Batch 1:  loss:1.316641926765442 accuracy:0.5641891956329346\n",
      "Epoch 84, CIFAR-10 Batch 1:  loss:1.3245763778686523 accuracy:0.5641891956329346\n",
      "Epoch 85, CIFAR-10 Batch 1:  loss:1.3233535289764404 accuracy:0.5743243098258972\n",
      "Epoch 86, CIFAR-10 Batch 1:  loss:1.295092225074768 accuracy:0.5743243098258972\n",
      "Epoch 87, CIFAR-10 Batch 1:  loss:1.288339614868164 accuracy:0.5709459185600281\n",
      "Epoch 88, CIFAR-10 Batch 1:  loss:1.281733751296997 accuracy:0.5844594836235046\n",
      "Epoch 89, CIFAR-10 Batch 1:  loss:1.2804323434829712 accuracy:0.5912162065505981\n",
      "Epoch 90, CIFAR-10 Batch 1:  loss:1.26442289352417 accuracy:0.587837815284729\n",
      "Epoch 91, CIFAR-10 Batch 1:  loss:1.273412823677063 accuracy:0.5709459185600281\n",
      "Epoch 92, CIFAR-10 Batch 1:  loss:1.2568329572677612 accuracy:0.6081081032752991\n",
      "Epoch 93, CIFAR-10 Batch 1:  loss:1.227321982383728 accuracy:0.5574324131011963\n",
      "Epoch 94, CIFAR-10 Batch 1:  loss:1.2132854461669922 accuracy:0.6182432174682617\n",
      "Epoch 95, CIFAR-10 Batch 1:  loss:1.2147738933563232 accuracy:0.5810810923576355\n",
      "Epoch 96, CIFAR-10 Batch 1:  loss:1.2032583951950073 accuracy:0.5979729890823364\n",
      "Epoch 97, CIFAR-10 Batch 1:  loss:1.201436996459961 accuracy:0.5979729890823364\n",
      "Epoch 98, CIFAR-10 Batch 1:  loss:1.2033493518829346 accuracy:0.6081081032752991\n",
      "Epoch 99, CIFAR-10 Batch 1:  loss:1.1943423748016357 accuracy:0.5945945978164673\n",
      "Epoch 100, CIFAR-10 Batch 1:  loss:1.1897823810577393 accuracy:0.6013513803482056\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss:10.945113182067871 accuracy:0.23648647964000702\n",
      "Epoch  1, CIFAR-10 Batch 2:  loss:2.3312244415283203 accuracy:     0.125\n",
      "Epoch  1, CIFAR-10 Batch 3:  loss:2.2759177684783936 accuracy:0.14527027308940887\n",
      "Epoch  1, CIFAR-10 Batch 4:  loss:2.239290714263916 accuracy:0.20945945382118225\n",
      "Epoch  1, CIFAR-10 Batch 5:  loss:2.246819257736206 accuracy:0.2060810774564743\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss:2.225046157836914 accuracy:0.1689189225435257\n",
      "Epoch  2, CIFAR-10 Batch 2:  loss:2.1748435497283936 accuracy:0.23310810327529907\n",
      "Epoch  2, CIFAR-10 Batch 3:  loss:2.1661112308502197 accuracy:      0.25\n",
      "Epoch  2, CIFAR-10 Batch 4:  loss:2.122249126434326 accuracy:0.2736486494541168\n",
      "Epoch  2, CIFAR-10 Batch 5:  loss:2.1085047721862793 accuracy:0.2668918967247009\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss:2.1201963424682617 accuracy:0.23310810327529907\n",
      "Epoch  3, CIFAR-10 Batch 2:  loss:2.0735831260681152 accuracy:0.2736486494541168\n",
      "Epoch  3, CIFAR-10 Batch 3:  loss:2.055785655975342 accuracy:0.2804054021835327\n",
      "Epoch  3, CIFAR-10 Batch 4:  loss:2.0332870483398438 accuracy:0.2871621549129486\n",
      "Epoch  3, CIFAR-10 Batch 5:  loss:2.037738800048828 accuracy:0.2736486494541168\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss:2.066417694091797 accuracy:0.24662162363529205\n",
      "Epoch  4, CIFAR-10 Batch 2:  loss:2.012563705444336 accuracy:0.2871621549129486\n",
      "Epoch  4, CIFAR-10 Batch 3:  loss:1.9982638359069824 accuracy:0.29054054617881775\n",
      "Epoch  4, CIFAR-10 Batch 4:  loss:1.9776393175125122 accuracy:0.2871621549129486\n",
      "Epoch  4, CIFAR-10 Batch 5:  loss:1.9934570789337158 accuracy:0.26013514399528503\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss:2.044219970703125 accuracy:0.2635135054588318\n",
      "Epoch  5, CIFAR-10 Batch 2:  loss:1.98075532913208 accuracy:0.29054054617881775\n",
      "Epoch  5, CIFAR-10 Batch 3:  loss:1.9687042236328125 accuracy:0.32094594836235046\n",
      "Epoch  5, CIFAR-10 Batch 4:  loss:1.9481580257415771 accuracy:0.2939189076423645\n",
      "Epoch  5, CIFAR-10 Batch 5:  loss:1.9547045230865479 accuracy:0.31081080436706543\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss:2.0319247245788574 accuracy:0.22972972691059113\n",
      "Epoch  6, CIFAR-10 Batch 2:  loss:1.928437352180481 accuracy:0.3175675570964813\n",
      "Epoch  6, CIFAR-10 Batch 3:  loss:1.9139575958251953 accuracy:0.32770270109176636\n",
      "Epoch  6, CIFAR-10 Batch 4:  loss:1.8975598812103271 accuracy:0.29729729890823364\n",
      "Epoch  6, CIFAR-10 Batch 5:  loss:1.9213192462921143 accuracy:0.29729729890823364\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss:1.9945794343948364 accuracy:0.22635135054588318\n",
      "Epoch  7, CIFAR-10 Batch 2:  loss:1.881983995437622 accuracy:0.3074324429035187\n",
      "Epoch  7, CIFAR-10 Batch 3:  loss:1.8548967838287354 accuracy:0.37162160873413086\n",
      "Epoch  7, CIFAR-10 Batch 4:  loss:1.84324312210083 accuracy:0.2871621549129486\n",
      "Epoch  7, CIFAR-10 Batch 5:  loss:1.8849167823791504 accuracy:0.33445945382118225\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss:1.954293966293335 accuracy:0.22972972691059113\n",
      "Epoch  8, CIFAR-10 Batch 2:  loss:1.8418684005737305 accuracy:0.31418919563293457\n",
      "Epoch  8, CIFAR-10 Batch 3:  loss:1.7939342260360718 accuracy:0.41554054617881775\n",
      "Epoch  8, CIFAR-10 Batch 4:  loss:1.8134957551956177 accuracy:0.31081080436706543\n",
      "Epoch  8, CIFAR-10 Batch 5:  loss:1.8501657247543335 accuracy:0.3074324429035187\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss:1.960908055305481 accuracy:      0.25\n",
      "Epoch  9, CIFAR-10 Batch 2:  loss:1.8178207874298096 accuracy:0.34797295928001404\n",
      "Epoch  9, CIFAR-10 Batch 3:  loss:1.7511101961135864 accuracy:0.40878379344940186\n",
      "Epoch  9, CIFAR-10 Batch 4:  loss:1.7817178964614868 accuracy:0.3513513505458832\n",
      "Epoch  9, CIFAR-10 Batch 5:  loss:1.8075363636016846 accuracy:0.3006756901741028\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss:1.9172897338867188 accuracy:0.25337839126586914\n",
      "Epoch 10, CIFAR-10 Batch 2:  loss:1.7878957986831665 accuracy:0.3513513505458832\n",
      "Epoch 10, CIFAR-10 Batch 3:  loss:1.7101372480392456 accuracy:0.40878379344940186\n",
      "Epoch 10, CIFAR-10 Batch 4:  loss:1.722865343093872 accuracy:0.37837839126586914\n",
      "Epoch 10, CIFAR-10 Batch 5:  loss:1.7650022506713867 accuracy:0.34797295928001404\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss:1.8672714233398438 accuracy:0.2736486494541168\n",
      "Epoch 11, CIFAR-10 Batch 2:  loss:1.7785898447036743 accuracy:0.34797295928001404\n",
      "Epoch 11, CIFAR-10 Batch 3:  loss:1.6786531209945679 accuracy:0.4324324429035187\n",
      "Epoch 11, CIFAR-10 Batch 4:  loss:1.667454481124878 accuracy:0.3986486494541168\n",
      "Epoch 11, CIFAR-10 Batch 5:  loss:1.7339143753051758 accuracy:0.3885135054588318\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss:1.8544503450393677 accuracy:0.3074324429035187\n",
      "Epoch 12, CIFAR-10 Batch 2:  loss:1.7510437965393066 accuracy:     0.375\n",
      "Epoch 12, CIFAR-10 Batch 3:  loss:1.6707066297531128 accuracy:0.4324324429035187\n",
      "Epoch 12, CIFAR-10 Batch 4:  loss:1.651219129562378 accuracy:0.40878379344940186\n",
      "Epoch 12, CIFAR-10 Batch 5:  loss:1.7339180707931519 accuracy:0.3885135054588318\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss:1.8351869583129883 accuracy:0.3310810923576355\n",
      "Epoch 13, CIFAR-10 Batch 2:  loss:1.717490315437317 accuracy:0.3817567527294159\n",
      "Epoch 13, CIFAR-10 Batch 3:  loss:1.6362224817276 accuracy:0.4324324429035187\n",
      "Epoch 13, CIFAR-10 Batch 4:  loss:1.6217420101165771 accuracy:0.4121621549129486\n",
      "Epoch 13, CIFAR-10 Batch 5:  loss:1.6784900426864624 accuracy:0.37837839126586914\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss:1.7903611660003662 accuracy:0.3581081032752991\n",
      "Epoch 14, CIFAR-10 Batch 2:  loss:1.700330138206482 accuracy:0.38513514399528503\n",
      "Epoch 14, CIFAR-10 Batch 3:  loss:1.6050422191619873 accuracy:0.4560810923576355\n",
      "Epoch 14, CIFAR-10 Batch 4:  loss:1.5696414709091187 accuracy:0.4121621549129486\n",
      "Epoch 14, CIFAR-10 Batch 5:  loss:1.6656612157821655 accuracy:0.3918918967247009\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss:1.7679686546325684 accuracy:0.36486485600471497\n",
      "Epoch 15, CIFAR-10 Batch 2:  loss:1.6834919452667236 accuracy:0.41554054617881775\n",
      "Epoch 15, CIFAR-10 Batch 3:  loss:1.5943864583969116 accuracy:0.4425675570964813\n",
      "Epoch 15, CIFAR-10 Batch 4:  loss:1.5491611957550049 accuracy:0.4425675570964813\n",
      "Epoch 15, CIFAR-10 Batch 5:  loss:1.6582777500152588 accuracy:0.40202704071998596\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss:1.7489299774169922 accuracy:0.3817567527294159\n",
      "Epoch 16, CIFAR-10 Batch 2:  loss:1.6680219173431396 accuracy:0.4121621549129486\n",
      "Epoch 16, CIFAR-10 Batch 3:  loss:1.592238187789917 accuracy:0.4256756901741028\n",
      "Epoch 16, CIFAR-10 Batch 4:  loss:1.5318920612335205 accuracy:0.4493243098258972\n",
      "Epoch 16, CIFAR-10 Batch 5:  loss:1.6023350954055786 accuracy:0.4121621549129486\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss:1.7266175746917725 accuracy:0.3918918967247009\n",
      "Epoch 17, CIFAR-10 Batch 2:  loss:1.6574029922485352 accuracy:0.3986486494541168\n",
      "Epoch 17, CIFAR-10 Batch 3:  loss:1.5480101108551025 accuracy:0.4695945978164673\n",
      "Epoch 17, CIFAR-10 Batch 4:  loss:1.5244132280349731 accuracy:0.3918918967247009\n",
      "Epoch 17, CIFAR-10 Batch 5:  loss:1.5980595350265503 accuracy:0.45945945382118225\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss:1.708578109741211 accuracy:0.3817567527294159\n",
      "Epoch 18, CIFAR-10 Batch 2:  loss:1.639826774597168 accuracy:0.4189189076423645\n",
      "Epoch 18, CIFAR-10 Batch 3:  loss:1.5168335437774658 accuracy:0.4797297418117523\n",
      "Epoch 18, CIFAR-10 Batch 4:  loss:1.5055965185165405 accuracy:0.4763513505458832\n",
      "Epoch 18, CIFAR-10 Batch 5:  loss:1.602441430091858 accuracy:0.4493243098258972\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss:1.6672916412353516 accuracy:0.40878379344940186\n",
      "Epoch 19, CIFAR-10 Batch 2:  loss:1.6067218780517578 accuracy:0.4256756901741028\n",
      "Epoch 19, CIFAR-10 Batch 3:  loss:1.497977375984192 accuracy:0.4425675570964813\n",
      "Epoch 19, CIFAR-10 Batch 4:  loss:1.4571349620819092 accuracy:0.4831081032752991\n",
      "Epoch 19, CIFAR-10 Batch 5:  loss:1.6001216173171997 accuracy:0.4256756901741028\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss:1.6499600410461426 accuracy:0.41554054617881775\n",
      "Epoch 20, CIFAR-10 Batch 2:  loss:1.6137347221374512 accuracy:0.4256756901741028\n",
      "Epoch 20, CIFAR-10 Batch 3:  loss:1.495255708694458 accuracy:0.4831081032752991\n",
      "Epoch 20, CIFAR-10 Batch 4:  loss:1.4477733373641968 accuracy:0.47297295928001404\n",
      "Epoch 20, CIFAR-10 Batch 5:  loss:1.5793877840042114 accuracy:0.42229729890823364\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss:1.6178889274597168 accuracy:0.42905405163764954\n",
      "Epoch 21, CIFAR-10 Batch 2:  loss:1.5933698415756226 accuracy:0.43918919563293457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, CIFAR-10 Batch 3:  loss:1.4630415439605713 accuracy:0.47297295928001404\n",
      "Epoch 21, CIFAR-10 Batch 4:  loss:1.4376364946365356 accuracy:0.4932432472705841\n",
      "Epoch 21, CIFAR-10 Batch 5:  loss:1.5613809823989868 accuracy:0.45945945382118225\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss:1.6269512176513672 accuracy:0.4121621549129486\n",
      "Epoch 22, CIFAR-10 Batch 2:  loss:1.6054695844650269 accuracy:0.4628378450870514\n",
      "Epoch 22, CIFAR-10 Batch 3:  loss:1.456220030784607 accuracy:0.4763513505458832\n",
      "Epoch 22, CIFAR-10 Batch 4:  loss:1.4128165245056152 accuracy:0.4763513505458832\n",
      "Epoch 22, CIFAR-10 Batch 5:  loss:1.5418788194656372 accuracy:0.45270270109176636\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss:1.5858614444732666 accuracy:0.44594594836235046\n",
      "Epoch 23, CIFAR-10 Batch 2:  loss:1.568345308303833 accuracy:0.44594594836235046\n",
      "Epoch 23, CIFAR-10 Batch 3:  loss:1.4460805654525757 accuracy:0.48986485600471497\n",
      "Epoch 23, CIFAR-10 Batch 4:  loss:1.4034621715545654 accuracy:0.4763513505458832\n",
      "Epoch 23, CIFAR-10 Batch 5:  loss:1.542803168296814 accuracy:0.4560810923576355\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss:1.5698411464691162 accuracy:0.4493243098258972\n",
      "Epoch 24, CIFAR-10 Batch 2:  loss:1.548931360244751 accuracy:0.4628378450870514\n",
      "Epoch 24, CIFAR-10 Batch 3:  loss:1.4296318292617798 accuracy:0.4695945978164673\n",
      "Epoch 24, CIFAR-10 Batch 4:  loss:1.3968720436096191 accuracy:0.4932432472705841\n",
      "Epoch 24, CIFAR-10 Batch 5:  loss:1.5295337438583374 accuracy:0.4695945978164673\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss:1.5721158981323242 accuracy:0.4324324429035187\n",
      "Epoch 25, CIFAR-10 Batch 2:  loss:1.545901894569397 accuracy:0.4628378450870514\n",
      "Epoch 25, CIFAR-10 Batch 3:  loss:1.41556978225708 accuracy:0.48986485600471497\n",
      "Epoch 25, CIFAR-10 Batch 4:  loss:1.3825186491012573 accuracy:0.48986485600471497\n",
      "Epoch 25, CIFAR-10 Batch 5:  loss:1.511998176574707 accuracy:0.4695945978164673\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss:1.5545505285263062 accuracy:0.44594594836235046\n",
      "Epoch 26, CIFAR-10 Batch 2:  loss:1.5194306373596191 accuracy:0.47297295928001404\n",
      "Epoch 26, CIFAR-10 Batch 3:  loss:1.3942203521728516 accuracy:0.5033783912658691\n",
      "Epoch 26, CIFAR-10 Batch 4:  loss:1.3652423620224 accuracy:0.47297295928001404\n",
      "Epoch 26, CIFAR-10 Batch 5:  loss:1.4943950176239014 accuracy:0.45945945382118225\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss:1.538038969039917 accuracy:0.45945945382118225\n",
      "Epoch 27, CIFAR-10 Batch 2:  loss:1.4896842241287231 accuracy:0.4695945978164673\n",
      "Epoch 27, CIFAR-10 Batch 3:  loss:1.378348708152771 accuracy:0.5236486196517944\n",
      "Epoch 27, CIFAR-10 Batch 4:  loss:1.355302333831787 accuracy:0.49662160873413086\n",
      "Epoch 27, CIFAR-10 Batch 5:  loss:1.479966402053833 accuracy:0.4831081032752991\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss:1.5251564979553223 accuracy:0.4695945978164673\n",
      "Epoch 28, CIFAR-10 Batch 2:  loss:1.514896035194397 accuracy:0.46621620655059814\n",
      "Epoch 28, CIFAR-10 Batch 3:  loss:1.3698698282241821 accuracy:0.5135135054588318\n",
      "Epoch 28, CIFAR-10 Batch 4:  loss:1.3359575271606445 accuracy:0.5202702879905701\n",
      "Epoch 28, CIFAR-10 Batch 5:  loss:1.4777393341064453 accuracy:0.5033783912658691\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss:1.5110690593719482 accuracy:0.4493243098258972\n",
      "Epoch 29, CIFAR-10 Batch 2:  loss:1.4819415807724 accuracy:0.43918919563293457\n",
      "Epoch 29, CIFAR-10 Batch 3:  loss:1.3125685453414917 accuracy:0.5405405163764954\n",
      "Epoch 29, CIFAR-10 Batch 4:  loss:1.3262238502502441 accuracy:0.5101351141929626\n",
      "Epoch 29, CIFAR-10 Batch 5:  loss:1.4385629892349243 accuracy:0.4831081032752991\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss:1.4872300624847412 accuracy:0.47297295928001404\n",
      "Epoch 30, CIFAR-10 Batch 2:  loss:1.4853297472000122 accuracy:0.47297295928001404\n",
      "Epoch 30, CIFAR-10 Batch 3:  loss:1.3249248266220093 accuracy:0.537162184715271\n",
      "Epoch 30, CIFAR-10 Batch 4:  loss:1.3063175678253174 accuracy:0.5168918967247009\n",
      "Epoch 30, CIFAR-10 Batch 5:  loss:1.4343230724334717 accuracy:0.5067567825317383\n",
      "Epoch 31, CIFAR-10 Batch 1:  loss:1.483637809753418 accuracy:0.4797297418117523\n",
      "Epoch 31, CIFAR-10 Batch 2:  loss:1.4454361200332642 accuracy:0.4831081032752991\n",
      "Epoch 31, CIFAR-10 Batch 3:  loss:1.2974694967269897 accuracy:0.5506756901741028\n",
      "Epoch 31, CIFAR-10 Batch 4:  loss:1.300542950630188 accuracy:0.5304054021835327\n",
      "Epoch 31, CIFAR-10 Batch 5:  loss:1.4214162826538086 accuracy:0.48986485600471497\n",
      "Epoch 32, CIFAR-10 Batch 1:  loss:1.4659749269485474 accuracy:0.45945945382118225\n",
      "Epoch 32, CIFAR-10 Batch 2:  loss:1.4334043264389038 accuracy:0.48986485600471497\n",
      "Epoch 32, CIFAR-10 Batch 3:  loss:1.2488130331039429 accuracy:0.5405405163764954\n",
      "Epoch 32, CIFAR-10 Batch 4:  loss:1.2831449508666992 accuracy:0.5067567825317383\n",
      "Epoch 32, CIFAR-10 Batch 5:  loss:1.4057751893997192 accuracy:0.4797297418117523\n",
      "Epoch 33, CIFAR-10 Batch 1:  loss:1.45542311668396 accuracy:0.4628378450870514\n",
      "Epoch 33, CIFAR-10 Batch 2:  loss:1.432093620300293 accuracy:0.5236486196517944\n",
      "Epoch 33, CIFAR-10 Batch 3:  loss:1.221273422241211 accuracy:0.5709459185600281\n",
      "Epoch 33, CIFAR-10 Batch 4:  loss:1.2608662843704224 accuracy:0.5405405163764954\n",
      "Epoch 33, CIFAR-10 Batch 5:  loss:1.394944429397583 accuracy:0.46621620655059814\n",
      "Epoch 34, CIFAR-10 Batch 1:  loss:1.4289182424545288 accuracy:0.4763513505458832\n",
      "Epoch 34, CIFAR-10 Batch 2:  loss:1.4126685857772827 accuracy:0.4763513505458832\n",
      "Epoch 34, CIFAR-10 Batch 3:  loss:1.2305493354797363 accuracy:0.5405405163764954\n",
      "Epoch 34, CIFAR-10 Batch 4:  loss:1.2404284477233887 accuracy:0.587837815284729\n",
      "Epoch 34, CIFAR-10 Batch 5:  loss:1.5409400463104248 accuracy:0.47297295928001404\n",
      "Epoch 35, CIFAR-10 Batch 1:  loss:1.4179822206497192 accuracy:0.4763513505458832\n",
      "Epoch 35, CIFAR-10 Batch 2:  loss:1.4185911417007446 accuracy:0.4797297418117523\n",
      "Epoch 35, CIFAR-10 Batch 3:  loss:1.2045389413833618 accuracy:0.5844594836235046\n",
      "Epoch 35, CIFAR-10 Batch 4:  loss:1.2422629594802856 accuracy:0.5067567825317383\n",
      "Epoch 35, CIFAR-10 Batch 5:  loss:1.3692240715026855 accuracy:0.4932432472705841\n",
      "Epoch 36, CIFAR-10 Batch 1:  loss:1.3881781101226807 accuracy:0.4831081032752991\n",
      "Epoch 36, CIFAR-10 Batch 2:  loss:1.3638299703598022 accuracy:0.5101351141929626\n",
      "Epoch 36, CIFAR-10 Batch 3:  loss:1.191481351852417 accuracy:0.5608108043670654\n",
      "Epoch 36, CIFAR-10 Batch 4:  loss:1.2337188720703125 accuracy:0.537162184715271\n",
      "Epoch 36, CIFAR-10 Batch 5:  loss:1.3575810194015503 accuracy:0.4763513505458832\n",
      "Epoch 37, CIFAR-10 Batch 1:  loss:1.3792911767959595 accuracy:       0.5\n",
      "Epoch 37, CIFAR-10 Batch 2:  loss:1.3648048639297485 accuracy:0.5067567825317383\n",
      "Epoch 37, CIFAR-10 Batch 3:  loss:1.1795316934585571 accuracy:0.5777027010917664\n",
      "Epoch 37, CIFAR-10 Batch 4:  loss:1.2271360158920288 accuracy:0.5675675868988037\n",
      "Epoch 37, CIFAR-10 Batch 5:  loss:1.3407151699066162 accuracy:0.4932432472705841\n",
      "Epoch 38, CIFAR-10 Batch 1:  loss:1.3717411756515503 accuracy:0.48986485600471497\n",
      "Epoch 38, CIFAR-10 Batch 2:  loss:1.3549948930740356 accuracy:0.5270270109176636\n",
      "Epoch 38, CIFAR-10 Batch 3:  loss:1.1888929605484009 accuracy:0.6047297120094299\n",
      "Epoch 38, CIFAR-10 Batch 4:  loss:1.2091419696807861 accuracy:0.5641891956329346\n",
      "Epoch 38, CIFAR-10 Batch 5:  loss:1.3183292150497437 accuracy:       0.5\n",
      "Epoch 39, CIFAR-10 Batch 1:  loss:1.3572989702224731 accuracy:0.4864864945411682\n",
      "Epoch 39, CIFAR-10 Batch 2:  loss:1.3445587158203125 accuracy:0.5304054021835327\n",
      "Epoch 39, CIFAR-10 Batch 3:  loss:1.1613255739212036 accuracy:0.6182432174682617\n",
      "Epoch 39, CIFAR-10 Batch 4:  loss:1.2078933715820312 accuracy:0.5675675868988037\n",
      "Epoch 39, CIFAR-10 Batch 5:  loss:1.3224363327026367 accuracy:0.5101351141929626\n",
      "Epoch 40, CIFAR-10 Batch 1:  loss:1.3534181118011475 accuracy:0.5033783912658691\n",
      "Epoch 40, CIFAR-10 Batch 2:  loss:1.3378456830978394 accuracy:0.5135135054588318\n",
      "Epoch 40, CIFAR-10 Batch 3:  loss:1.1449081897735596 accuracy:0.6013513803482056\n",
      "Epoch 40, CIFAR-10 Batch 4:  loss:1.1757144927978516 accuracy:0.5641891956329346\n",
      "Epoch 40, CIFAR-10 Batch 5:  loss:1.3118641376495361 accuracy:0.5168918967247009\n",
      "Epoch 41, CIFAR-10 Batch 1:  loss:1.3641289472579956 accuracy:0.49662160873413086\n",
      "Epoch 41, CIFAR-10 Batch 2:  loss:1.337895393371582 accuracy:0.5439189076423645\n",
      "Epoch 41, CIFAR-10 Batch 3:  loss:1.141586422920227 accuracy:0.5945945978164673\n",
      "Epoch 41, CIFAR-10 Batch 4:  loss:1.2043880224227905 accuracy:0.5810810923576355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, CIFAR-10 Batch 5:  loss:1.2919381856918335 accuracy:0.5304054021835327\n",
      "Epoch 42, CIFAR-10 Batch 1:  loss:1.3621991872787476 accuracy:0.4932432472705841\n",
      "Epoch 42, CIFAR-10 Batch 2:  loss:1.3086398839950562 accuracy:0.5270270109176636\n",
      "Epoch 42, CIFAR-10 Batch 3:  loss:1.1238219738006592 accuracy:0.6013513803482056\n",
      "Epoch 42, CIFAR-10 Batch 4:  loss:1.1726624965667725 accuracy:0.5777027010917664\n",
      "Epoch 42, CIFAR-10 Batch 5:  loss:1.2812297344207764 accuracy:0.5236486196517944\n",
      "Epoch 43, CIFAR-10 Batch 1:  loss:1.3209655284881592 accuracy:0.537162184715271\n",
      "Epoch 43, CIFAR-10 Batch 2:  loss:1.2869617938995361 accuracy:0.5506756901741028\n",
      "Epoch 43, CIFAR-10 Batch 3:  loss:1.1104097366333008 accuracy:0.6013513803482056\n",
      "Epoch 43, CIFAR-10 Batch 4:  loss:1.1560838222503662 accuracy:0.5675675868988037\n",
      "Epoch 43, CIFAR-10 Batch 5:  loss:1.2575489282608032 accuracy:0.5304054021835327\n",
      "Epoch 44, CIFAR-10 Batch 1:  loss:1.3027595281600952 accuracy:0.5405405163764954\n",
      "Epoch 44, CIFAR-10 Batch 2:  loss:1.305863618850708 accuracy:0.5337837934494019\n",
      "Epoch 44, CIFAR-10 Batch 3:  loss:1.0832620859146118 accuracy:0.5979729890823364\n",
      "Epoch 44, CIFAR-10 Batch 4:  loss:1.1649843454360962 accuracy:0.5945945978164673\n",
      "Epoch 44, CIFAR-10 Batch 5:  loss:1.24553644657135 accuracy:0.5202702879905701\n",
      "Epoch 45, CIFAR-10 Batch 1:  loss:1.289568305015564 accuracy:0.5405405163764954\n",
      "Epoch 45, CIFAR-10 Batch 2:  loss:1.2790424823760986 accuracy:0.5506756901741028\n",
      "Epoch 45, CIFAR-10 Batch 3:  loss:1.0896360874176025 accuracy:0.6216216087341309\n",
      "Epoch 45, CIFAR-10 Batch 4:  loss:1.1436086893081665 accuracy:0.5844594836235046\n",
      "Epoch 45, CIFAR-10 Batch 5:  loss:1.229491114616394 accuracy:0.5472972989082336\n",
      "Epoch 46, CIFAR-10 Batch 1:  loss:1.287074327468872 accuracy:0.5506756901741028\n",
      "Epoch 46, CIFAR-10 Batch 2:  loss:1.2820618152618408 accuracy:0.5067567825317383\n",
      "Epoch 46, CIFAR-10 Batch 3:  loss:1.0872974395751953 accuracy:0.6520270109176636\n",
      "Epoch 46, CIFAR-10 Batch 4:  loss:1.114527940750122 accuracy:0.5945945978164673\n",
      "Epoch 46, CIFAR-10 Batch 5:  loss:1.1935467720031738 accuracy:0.5608108043670654\n",
      "Epoch 47, CIFAR-10 Batch 1:  loss:1.2879760265350342 accuracy:0.5675675868988037\n",
      "Epoch 47, CIFAR-10 Batch 2:  loss:1.2647820711135864 accuracy:0.5472972989082336\n",
      "Epoch 47, CIFAR-10 Batch 3:  loss:1.0633962154388428 accuracy:0.6385135054588318\n",
      "Epoch 47, CIFAR-10 Batch 4:  loss:1.1063371896743774 accuracy:0.5979729890823364\n",
      "Epoch 47, CIFAR-10 Batch 5:  loss:1.217400074005127 accuracy:0.5506756901741028\n",
      "Epoch 48, CIFAR-10 Batch 1:  loss:1.2809996604919434 accuracy:0.5506756901741028\n",
      "Epoch 48, CIFAR-10 Batch 2:  loss:1.2385612726211548 accuracy:0.5337837934494019\n",
      "Epoch 48, CIFAR-10 Batch 3:  loss:1.0733906030654907 accuracy:0.5979729890823364\n",
      "Epoch 48, CIFAR-10 Batch 4:  loss:1.10276460647583 accuracy:0.6013513803482056\n",
      "Epoch 48, CIFAR-10 Batch 5:  loss:1.1864750385284424 accuracy:0.5506756901741028\n",
      "Epoch 49, CIFAR-10 Batch 1:  loss:1.2536215782165527 accuracy:0.5540540814399719\n",
      "Epoch 49, CIFAR-10 Batch 2:  loss:1.2215367555618286 accuracy:0.5641891956329346\n",
      "Epoch 49, CIFAR-10 Batch 3:  loss:1.0189647674560547 accuracy:0.6216216087341309\n",
      "Epoch 49, CIFAR-10 Batch 4:  loss:1.112385630607605 accuracy:0.5743243098258972\n",
      "Epoch 49, CIFAR-10 Batch 5:  loss:1.1960632801055908 accuracy:0.5540540814399719\n",
      "Epoch 50, CIFAR-10 Batch 1:  loss:1.2641369104385376 accuracy:0.5743243098258972\n",
      "Epoch 50, CIFAR-10 Batch 2:  loss:1.2031867504119873 accuracy:0.5641891956329346\n",
      "Epoch 50, CIFAR-10 Batch 3:  loss:1.0522178411483765 accuracy:     0.625\n",
      "Epoch 50, CIFAR-10 Batch 4:  loss:1.0806982517242432 accuracy:0.6283783912658691\n",
      "Epoch 50, CIFAR-10 Batch 5:  loss:1.1460545063018799 accuracy:0.5810810923576355\n",
      "Epoch 51, CIFAR-10 Batch 1:  loss:1.235942006111145 accuracy:0.5709459185600281\n",
      "Epoch 51, CIFAR-10 Batch 2:  loss:1.1972697973251343 accuracy:0.5304054021835327\n",
      "Epoch 51, CIFAR-10 Batch 3:  loss:1.0329822301864624 accuracy:0.6216216087341309\n",
      "Epoch 51, CIFAR-10 Batch 4:  loss:1.096959114074707 accuracy:0.6047297120094299\n",
      "Epoch 51, CIFAR-10 Batch 5:  loss:1.1325311660766602 accuracy:0.5810810923576355\n",
      "Epoch 52, CIFAR-10 Batch 1:  loss:1.261466383934021 accuracy:0.5574324131011963\n",
      "Epoch 52, CIFAR-10 Batch 2:  loss:1.218110203742981 accuracy:0.5405405163764954\n",
      "Epoch 52, CIFAR-10 Batch 3:  loss:1.035565733909607 accuracy:0.6216216087341309\n",
      "Epoch 52, CIFAR-10 Batch 4:  loss:1.0857375860214233 accuracy:0.6013513803482056\n",
      "Epoch 52, CIFAR-10 Batch 5:  loss:1.1483502388000488 accuracy:0.5777027010917664\n",
      "Epoch 53, CIFAR-10 Batch 1:  loss:1.1954578161239624 accuracy:0.5777027010917664\n",
      "Epoch 53, CIFAR-10 Batch 2:  loss:1.1683405637741089 accuracy:0.5844594836235046\n",
      "Epoch 53, CIFAR-10 Batch 3:  loss:1.0311449766159058 accuracy:0.6385135054588318\n",
      "Epoch 53, CIFAR-10 Batch 4:  loss:1.0618107318878174 accuracy:0.6182432174682617\n",
      "Epoch 53, CIFAR-10 Batch 5:  loss:1.1290384531021118 accuracy:0.5810810923576355\n",
      "Epoch 54, CIFAR-10 Batch 1:  loss:1.1981443166732788 accuracy:0.6182432174682617\n",
      "Epoch 54, CIFAR-10 Batch 2:  loss:1.1581380367279053 accuracy:0.5709459185600281\n",
      "Epoch 54, CIFAR-10 Batch 3:  loss:1.001099944114685 accuracy:0.6486486196517944\n",
      "Epoch 54, CIFAR-10 Batch 4:  loss:1.0443615913391113 accuracy:0.6283783912658691\n",
      "Epoch 54, CIFAR-10 Batch 5:  loss:1.109731912612915 accuracy:0.587837815284729\n",
      "Epoch 55, CIFAR-10 Batch 1:  loss:1.1706620454788208 accuracy:0.5912162065505981\n",
      "Epoch 55, CIFAR-10 Batch 2:  loss:1.1729079484939575 accuracy:0.587837815284729\n",
      "Epoch 55, CIFAR-10 Batch 3:  loss:0.9878414273262024 accuracy:0.6452702879905701\n",
      "Epoch 55, CIFAR-10 Batch 4:  loss:1.0663090944290161 accuracy:0.6216216087341309\n",
      "Epoch 55, CIFAR-10 Batch 5:  loss:1.0880824327468872 accuracy:0.6114864945411682\n",
      "Epoch 56, CIFAR-10 Batch 1:  loss:1.142547845840454 accuracy:0.6148648858070374\n",
      "Epoch 56, CIFAR-10 Batch 2:  loss:1.1647816896438599 accuracy:0.5675675868988037\n",
      "Epoch 56, CIFAR-10 Batch 3:  loss:0.9787131547927856 accuracy:0.6283783912658691\n",
      "Epoch 56, CIFAR-10 Batch 4:  loss:1.0330315828323364 accuracy:0.6351351141929626\n",
      "Epoch 56, CIFAR-10 Batch 5:  loss:1.065563678741455 accuracy:0.6114864945411682\n",
      "Epoch 57, CIFAR-10 Batch 1:  loss:1.1453622579574585 accuracy:0.5844594836235046\n",
      "Epoch 57, CIFAR-10 Batch 2:  loss:1.1348179578781128 accuracy:0.5912162065505981\n",
      "Epoch 57, CIFAR-10 Batch 3:  loss:0.9499385952949524 accuracy:0.6554054021835327\n",
      "Epoch 57, CIFAR-10 Batch 4:  loss:1.0159752368927002 accuracy:0.6418918967247009\n",
      "Epoch 57, CIFAR-10 Batch 5:  loss:1.0951132774353027 accuracy:0.5945945978164673\n",
      "Epoch 58, CIFAR-10 Batch 1:  loss:1.1411205530166626 accuracy:0.6148648858070374\n",
      "Epoch 58, CIFAR-10 Batch 2:  loss:1.143723487854004 accuracy:0.5743243098258972\n",
      "Epoch 58, CIFAR-10 Batch 3:  loss:0.981694221496582 accuracy:0.6554054021835327\n",
      "Epoch 58, CIFAR-10 Batch 4:  loss:1.0166596174240112 accuracy:0.6486486196517944\n",
      "Epoch 58, CIFAR-10 Batch 5:  loss:1.0493615865707397 accuracy:0.5979729890823364\n",
      "Epoch 59, CIFAR-10 Batch 1:  loss:1.1223622560501099 accuracy:0.6385135054588318\n",
      "Epoch 59, CIFAR-10 Batch 2:  loss:1.1041781902313232 accuracy:0.6182432174682617\n",
      "Epoch 59, CIFAR-10 Batch 3:  loss:0.9343814253807068 accuracy:0.6587837934494019\n",
      "Epoch 59, CIFAR-10 Batch 4:  loss:1.0138123035430908 accuracy:0.6317567825317383\n",
      "Epoch 59, CIFAR-10 Batch 5:  loss:1.0282866954803467 accuracy:0.6148648858070374\n",
      "Epoch 60, CIFAR-10 Batch 1:  loss:1.1168429851531982 accuracy:     0.625\n",
      "Epoch 60, CIFAR-10 Batch 2:  loss:1.0912929773330688 accuracy:0.6013513803482056\n",
      "Epoch 60, CIFAR-10 Batch 3:  loss:0.9380130171775818 accuracy:0.6587837934494019\n",
      "Epoch 60, CIFAR-10 Batch 4:  loss:1.0000276565551758 accuracy:0.6452702879905701\n",
      "Epoch 60, CIFAR-10 Batch 5:  loss:1.0114434957504272 accuracy:0.6148648858070374\n",
      "Epoch 61, CIFAR-10 Batch 1:  loss:1.098646879196167 accuracy:0.6081081032752991\n",
      "Epoch 61, CIFAR-10 Batch 2:  loss:1.0792120695114136 accuracy:0.6114864945411682\n",
      "Epoch 61, CIFAR-10 Batch 3:  loss:0.9379022121429443 accuracy:0.6689189076423645\n",
      "Epoch 61, CIFAR-10 Batch 4:  loss:0.9838002324104309 accuracy:0.6756756901741028\n",
      "Epoch 61, CIFAR-10 Batch 5:  loss:1.0215823650360107 accuracy:0.6351351141929626\n",
      "Epoch 62, CIFAR-10 Batch 1:  loss:1.0768201351165771 accuracy:0.6182432174682617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, CIFAR-10 Batch 2:  loss:1.0729361772537231 accuracy:0.6114864945411682\n",
      "Epoch 62, CIFAR-10 Batch 3:  loss:0.9077473282814026 accuracy:0.6689189076423645\n",
      "Epoch 62, CIFAR-10 Batch 4:  loss:0.9829853177070618 accuracy:0.6418918967247009\n",
      "Epoch 62, CIFAR-10 Batch 5:  loss:1.0167587995529175 accuracy:0.6351351141929626\n",
      "Epoch 63, CIFAR-10 Batch 1:  loss:1.0894081592559814 accuracy:0.6081081032752991\n",
      "Epoch 63, CIFAR-10 Batch 2:  loss:1.060971736907959 accuracy:0.6081081032752991\n",
      "Epoch 63, CIFAR-10 Batch 3:  loss:0.9317651987075806 accuracy:0.662162184715271\n",
      "Epoch 63, CIFAR-10 Batch 4:  loss:0.967488169670105 accuracy:0.6554054021835327\n",
      "Epoch 63, CIFAR-10 Batch 5:  loss:1.006796956062317 accuracy:0.6385135054588318\n",
      "Epoch 64, CIFAR-10 Batch 1:  loss:1.0562938451766968 accuracy:0.6182432174682617\n",
      "Epoch 64, CIFAR-10 Batch 2:  loss:1.0372345447540283 accuracy:0.6216216087341309\n",
      "Epoch 64, CIFAR-10 Batch 3:  loss:0.9232558012008667 accuracy:0.6824324131011963\n",
      "Epoch 64, CIFAR-10 Batch 4:  loss:0.9626756906509399 accuracy:0.662162184715271\n",
      "Epoch 64, CIFAR-10 Batch 5:  loss:0.9790313243865967 accuracy:0.6452702879905701\n",
      "Epoch 65, CIFAR-10 Batch 1:  loss:1.066266417503357 accuracy:0.6114864945411682\n",
      "Epoch 65, CIFAR-10 Batch 2:  loss:1.035636067390442 accuracy:0.6385135054588318\n",
      "Epoch 65, CIFAR-10 Batch 3:  loss:0.8890693187713623 accuracy:0.6858108043670654\n",
      "Epoch 65, CIFAR-10 Batch 4:  loss:0.9496380686759949 accuracy:0.6993243098258972\n",
      "Epoch 65, CIFAR-10 Batch 5:  loss:0.970574140548706 accuracy:0.6520270109176636\n",
      "Epoch 66, CIFAR-10 Batch 1:  loss:1.0250988006591797 accuracy:0.6385135054588318\n",
      "Epoch 66, CIFAR-10 Batch 2:  loss:1.0220695734024048 accuracy:0.6385135054588318\n",
      "Epoch 66, CIFAR-10 Batch 3:  loss:0.8910341262817383 accuracy:0.6925675868988037\n",
      "Epoch 66, CIFAR-10 Batch 4:  loss:0.9563933610916138 accuracy:0.6756756901741028\n",
      "Epoch 66, CIFAR-10 Batch 5:  loss:0.9682862758636475 accuracy:0.6520270109176636\n",
      "Epoch 67, CIFAR-10 Batch 1:  loss:1.022419810295105 accuracy:0.6486486196517944\n",
      "Epoch 67, CIFAR-10 Batch 2:  loss:1.0012890100479126 accuracy:0.6452702879905701\n",
      "Epoch 67, CIFAR-10 Batch 3:  loss:0.8892477750778198 accuracy:0.6891891956329346\n",
      "Epoch 67, CIFAR-10 Batch 4:  loss:0.9163094758987427 accuracy:0.6790540814399719\n",
      "Epoch 67, CIFAR-10 Batch 5:  loss:0.9713580012321472 accuracy:0.6486486196517944\n",
      "Epoch 68, CIFAR-10 Batch 1:  loss:1.029435157775879 accuracy:0.6689189076423645\n",
      "Epoch 68, CIFAR-10 Batch 2:  loss:0.9855902194976807 accuracy:0.6418918967247009\n",
      "Epoch 68, CIFAR-10 Batch 3:  loss:0.8645017743110657 accuracy:0.6824324131011963\n",
      "Epoch 68, CIFAR-10 Batch 4:  loss:0.9229860305786133 accuracy:0.6790540814399719\n",
      "Epoch 68, CIFAR-10 Batch 5:  loss:0.9487581253051758 accuracy:0.6554054021835327\n",
      "Epoch 69, CIFAR-10 Batch 1:  loss:0.9838471412658691 accuracy:0.6587837934494019\n",
      "Epoch 69, CIFAR-10 Batch 2:  loss:0.9779695272445679 accuracy:0.6317567825317383\n",
      "Epoch 69, CIFAR-10 Batch 3:  loss:0.8706483840942383 accuracy:0.6959459185600281\n",
      "Epoch 69, CIFAR-10 Batch 4:  loss:0.9109453558921814 accuracy:0.6858108043670654\n",
      "Epoch 69, CIFAR-10 Batch 5:  loss:0.9493709206581116 accuracy:0.6351351141929626\n",
      "Epoch 70, CIFAR-10 Batch 1:  loss:0.9898281693458557 accuracy:0.6351351141929626\n",
      "Epoch 70, CIFAR-10 Batch 2:  loss:0.9699463844299316 accuracy:0.6520270109176636\n",
      "Epoch 70, CIFAR-10 Batch 3:  loss:0.8577210903167725 accuracy:0.6790540814399719\n",
      "Epoch 70, CIFAR-10 Batch 4:  loss:0.9018307328224182 accuracy:0.6824324131011963\n",
      "Epoch 70, CIFAR-10 Batch 5:  loss:0.9422361254692078 accuracy:0.6418918967247009\n",
      "Epoch 71, CIFAR-10 Batch 1:  loss:0.9769056439399719 accuracy:0.6655405163764954\n",
      "Epoch 71, CIFAR-10 Batch 2:  loss:0.9532266855239868 accuracy:0.6520270109176636\n",
      "Epoch 71, CIFAR-10 Batch 3:  loss:0.8586610555648804 accuracy:0.6993243098258972\n",
      "Epoch 71, CIFAR-10 Batch 4:  loss:0.8928205966949463 accuracy:0.6891891956329346\n",
      "Epoch 71, CIFAR-10 Batch 5:  loss:0.937474250793457 accuracy:0.6756756901741028\n",
      "Epoch 72, CIFAR-10 Batch 1:  loss:0.9693155884742737 accuracy:0.6587837934494019\n",
      "Epoch 72, CIFAR-10 Batch 2:  loss:0.9641563892364502 accuracy:0.6689189076423645\n",
      "Epoch 72, CIFAR-10 Batch 3:  loss:0.8600412607192993 accuracy:0.6925675868988037\n",
      "Epoch 72, CIFAR-10 Batch 4:  loss:0.8579495549201965 accuracy:0.6790540814399719\n",
      "Epoch 72, CIFAR-10 Batch 5:  loss:0.9059223532676697 accuracy:0.6756756901741028\n",
      "Epoch 73, CIFAR-10 Batch 1:  loss:0.9415286183357239 accuracy:0.6722972989082336\n",
      "Epoch 73, CIFAR-10 Batch 2:  loss:0.940699577331543 accuracy:0.6520270109176636\n",
      "Epoch 73, CIFAR-10 Batch 3:  loss:0.8423062562942505 accuracy:0.6858108043670654\n",
      "Epoch 73, CIFAR-10 Batch 4:  loss:0.8768240213394165 accuracy:0.6993243098258972\n",
      "Epoch 73, CIFAR-10 Batch 5:  loss:0.9044933915138245 accuracy:0.6824324131011963\n",
      "Epoch 74, CIFAR-10 Batch 1:  loss:0.9452435374259949 accuracy:0.6689189076423645\n",
      "Epoch 74, CIFAR-10 Batch 2:  loss:0.9464479684829712 accuracy:0.6587837934494019\n",
      "Epoch 74, CIFAR-10 Batch 3:  loss:0.8389875888824463 accuracy:0.6790540814399719\n",
      "Epoch 74, CIFAR-10 Batch 4:  loss:0.8693340420722961 accuracy:0.6993243098258972\n",
      "Epoch 74, CIFAR-10 Batch 5:  loss:0.9094345569610596 accuracy:0.6520270109176636\n",
      "Epoch 75, CIFAR-10 Batch 1:  loss:0.9254657626152039 accuracy:0.6790540814399719\n",
      "Epoch 75, CIFAR-10 Batch 2:  loss:0.925207793712616 accuracy:0.6689189076423645\n",
      "Epoch 75, CIFAR-10 Batch 3:  loss:0.8162971138954163 accuracy:0.6959459185600281\n",
      "Epoch 75, CIFAR-10 Batch 4:  loss:0.8610143661499023 accuracy:0.7094594836235046\n",
      "Epoch 75, CIFAR-10 Batch 5:  loss:0.8760340809822083 accuracy:0.6824324131011963\n",
      "Epoch 76, CIFAR-10 Batch 1:  loss:0.910706102848053 accuracy:0.6790540814399719\n",
      "Epoch 76, CIFAR-10 Batch 2:  loss:0.9117690324783325 accuracy:0.6655405163764954\n",
      "Epoch 76, CIFAR-10 Batch 3:  loss:0.8118286728858948 accuracy:0.7195945978164673\n",
      "Epoch 76, CIFAR-10 Batch 4:  loss:0.8454057574272156 accuracy:0.7229729890823364\n",
      "Epoch 76, CIFAR-10 Batch 5:  loss:0.8648473620414734 accuracy:0.6756756901741028\n",
      "Epoch 77, CIFAR-10 Batch 1:  loss:0.9087576866149902 accuracy:0.6959459185600281\n",
      "Epoch 77, CIFAR-10 Batch 2:  loss:0.9167417287826538 accuracy:0.6689189076423645\n",
      "Epoch 77, CIFAR-10 Batch 3:  loss:0.8142889738082886 accuracy:0.6925675868988037\n",
      "Epoch 77, CIFAR-10 Batch 4:  loss:0.8475154042243958 accuracy:0.6891891956329346\n",
      "Epoch 77, CIFAR-10 Batch 5:  loss:0.8509648442268372 accuracy:0.7027027010917664\n",
      "Epoch 78, CIFAR-10 Batch 1:  loss:0.9137662053108215 accuracy:0.6824324131011963\n",
      "Epoch 78, CIFAR-10 Batch 2:  loss:0.9076484441757202 accuracy:0.6689189076423645\n",
      "Epoch 78, CIFAR-10 Batch 3:  loss:0.7999433875083923 accuracy:0.6925675868988037\n",
      "Epoch 78, CIFAR-10 Batch 4:  loss:0.8453198671340942 accuracy:0.6959459185600281\n",
      "Epoch 78, CIFAR-10 Batch 5:  loss:0.8531485795974731 accuracy:0.6756756901741028\n",
      "Epoch 79, CIFAR-10 Batch 1:  loss:0.8899420499801636 accuracy:0.6925675868988037\n",
      "Epoch 79, CIFAR-10 Batch 2:  loss:0.8866937756538391 accuracy:0.6587837934494019\n",
      "Epoch 79, CIFAR-10 Batch 3:  loss:0.7914038896560669 accuracy:0.7195945978164673\n",
      "Epoch 79, CIFAR-10 Batch 4:  loss:0.8542158007621765 accuracy:0.6891891956329346\n",
      "Epoch 79, CIFAR-10 Batch 5:  loss:0.8564863204956055 accuracy:0.6824324131011963\n",
      "Epoch 80, CIFAR-10 Batch 1:  loss:0.8793538808822632 accuracy:0.6959459185600281\n",
      "Epoch 80, CIFAR-10 Batch 2:  loss:0.8673561811447144 accuracy:0.6824324131011963\n",
      "Epoch 80, CIFAR-10 Batch 3:  loss:0.7855786085128784 accuracy:0.6993243098258972\n",
      "Epoch 80, CIFAR-10 Batch 4:  loss:0.8219831585884094 accuracy:0.6993243098258972\n",
      "Epoch 80, CIFAR-10 Batch 5:  loss:0.8353627920150757 accuracy:0.6790540814399719\n",
      "Epoch 81, CIFAR-10 Batch 1:  loss:0.8758646249771118 accuracy:0.6891891956329346\n",
      "Epoch 81, CIFAR-10 Batch 2:  loss:0.8689061999320984 accuracy:0.6925675868988037\n",
      "Epoch 81, CIFAR-10 Batch 3:  loss:0.7763013243675232 accuracy:0.712837815284729\n",
      "Epoch 81, CIFAR-10 Batch 4:  loss:0.8051009178161621 accuracy:0.6891891956329346\n",
      "Epoch 81, CIFAR-10 Batch 5:  loss:0.8259899020195007 accuracy:0.6858108043670654\n",
      "Epoch 82, CIFAR-10 Batch 1:  loss:0.8601850271224976 accuracy:0.7060810923576355\n",
      "Epoch 82, CIFAR-10 Batch 2:  loss:0.8582884669303894 accuracy:0.7027027010917664\n",
      "Epoch 82, CIFAR-10 Batch 3:  loss:0.7599388957023621 accuracy:0.7060810923576355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, CIFAR-10 Batch 4:  loss:0.797498881816864 accuracy:0.712837815284729\n",
      "Epoch 82, CIFAR-10 Batch 5:  loss:0.8179723024368286 accuracy:0.7162162065505981\n",
      "Epoch 83, CIFAR-10 Batch 1:  loss:0.8371984362602234 accuracy:0.6993243098258972\n",
      "Epoch 83, CIFAR-10 Batch 2:  loss:0.8436266779899597 accuracy:0.6993243098258972\n",
      "Epoch 83, CIFAR-10 Batch 3:  loss:0.7603864073753357 accuracy:0.7229729890823364\n",
      "Epoch 83, CIFAR-10 Batch 4:  loss:0.777734637260437 accuracy:0.7364864945411682\n",
      "Epoch 83, CIFAR-10 Batch 5:  loss:0.7912437915802002 accuracy:0.6993243098258972\n",
      "Epoch 84, CIFAR-10 Batch 1:  loss:0.8199112415313721 accuracy:0.7195945978164673\n",
      "Epoch 84, CIFAR-10 Batch 2:  loss:0.8362107276916504 accuracy:0.7094594836235046\n",
      "Epoch 84, CIFAR-10 Batch 3:  loss:0.7557007670402527 accuracy:0.7297297120094299\n",
      "Epoch 84, CIFAR-10 Batch 4:  loss:0.7862512469291687 accuracy:0.7297297120094299\n",
      "Epoch 84, CIFAR-10 Batch 5:  loss:0.7926651239395142 accuracy:0.7027027010917664\n",
      "Epoch 85, CIFAR-10 Batch 1:  loss:0.8119874000549316 accuracy:0.6959459185600281\n",
      "Epoch 85, CIFAR-10 Batch 2:  loss:0.8179369568824768 accuracy:0.6790540814399719\n",
      "Epoch 85, CIFAR-10 Batch 3:  loss:0.7263450026512146 accuracy:0.7398648858070374\n",
      "Epoch 85, CIFAR-10 Batch 4:  loss:0.7838243246078491 accuracy:0.7297297120094299\n",
      "Epoch 85, CIFAR-10 Batch 5:  loss:0.7932963371276855 accuracy:0.6858108043670654\n",
      "Epoch 86, CIFAR-10 Batch 1:  loss:0.8137321472167969 accuracy:0.6959459185600281\n",
      "Epoch 86, CIFAR-10 Batch 2:  loss:0.7985469102859497 accuracy:0.7094594836235046\n",
      "Epoch 86, CIFAR-10 Batch 3:  loss:0.7423790097236633 accuracy:0.7162162065505981\n",
      "Epoch 86, CIFAR-10 Batch 4:  loss:0.7740587592124939 accuracy:0.7229729890823364\n",
      "Epoch 86, CIFAR-10 Batch 5:  loss:0.7762380838394165 accuracy:0.712837815284729\n",
      "Epoch 87, CIFAR-10 Batch 1:  loss:0.7992035746574402 accuracy:0.712837815284729\n",
      "Epoch 87, CIFAR-10 Batch 2:  loss:0.7939686179161072 accuracy:0.7162162065505981\n",
      "Epoch 87, CIFAR-10 Batch 3:  loss:0.7164114117622375 accuracy:0.7398648858070374\n",
      "Epoch 87, CIFAR-10 Batch 4:  loss:0.7796260714530945 accuracy:0.7229729890823364\n",
      "Epoch 87, CIFAR-10 Batch 5:  loss:0.7722021341323853 accuracy:0.7060810923576355\n",
      "Epoch 88, CIFAR-10 Batch 1:  loss:0.8048533201217651 accuracy:0.7162162065505981\n",
      "Epoch 88, CIFAR-10 Batch 2:  loss:0.8014200329780579 accuracy:0.7094594836235046\n",
      "Epoch 88, CIFAR-10 Batch 3:  loss:0.7104442119598389 accuracy:0.7466216087341309\n",
      "Epoch 88, CIFAR-10 Batch 4:  loss:0.7559104561805725 accuracy:0.7398648858070374\n",
      "Epoch 88, CIFAR-10 Batch 5:  loss:0.7665534019470215 accuracy:0.7027027010917664\n",
      "Epoch 89, CIFAR-10 Batch 1:  loss:0.7930372357368469 accuracy:0.6993243098258972\n",
      "Epoch 89, CIFAR-10 Batch 2:  loss:0.7856243848800659 accuracy:0.7027027010917664\n",
      "Epoch 89, CIFAR-10 Batch 3:  loss:0.6978626847267151 accuracy:0.7533783912658691\n",
      "Epoch 89, CIFAR-10 Batch 4:  loss:0.7647353410720825 accuracy:      0.75\n",
      "Epoch 89, CIFAR-10 Batch 5:  loss:0.7478570938110352 accuracy:0.7195945978164673\n",
      "Epoch 90, CIFAR-10 Batch 1:  loss:0.781093955039978 accuracy:0.7162162065505981\n",
      "Epoch 90, CIFAR-10 Batch 2:  loss:0.7856947183609009 accuracy:0.7094594836235046\n",
      "Epoch 90, CIFAR-10 Batch 3:  loss:0.7009745240211487 accuracy:0.7364864945411682\n",
      "Epoch 90, CIFAR-10 Batch 4:  loss:0.7401251792907715 accuracy:0.7533783912658691\n",
      "Epoch 90, CIFAR-10 Batch 5:  loss:0.7438542246818542 accuracy:0.7297297120094299\n",
      "Epoch 91, CIFAR-10 Batch 1:  loss:0.7574374675750732 accuracy:0.7263513803482056\n",
      "Epoch 91, CIFAR-10 Batch 2:  loss:0.7705324292182922 accuracy:0.7466216087341309\n",
      "Epoch 91, CIFAR-10 Batch 3:  loss:0.6794729232788086 accuracy:0.7601351141929626\n",
      "Epoch 91, CIFAR-10 Batch 4:  loss:0.728020966053009 accuracy:      0.75\n",
      "Epoch 91, CIFAR-10 Batch 5:  loss:0.7471069693565369 accuracy:0.7060810923576355\n",
      "Epoch 92, CIFAR-10 Batch 1:  loss:0.7865171432495117 accuracy:0.7094594836235046\n",
      "Epoch 92, CIFAR-10 Batch 2:  loss:0.7547361254692078 accuracy:0.7060810923576355\n",
      "Epoch 92, CIFAR-10 Batch 3:  loss:0.6988472938537598 accuracy:0.7398648858070374\n",
      "Epoch 92, CIFAR-10 Batch 4:  loss:0.7148283123970032 accuracy:0.7736486196517944\n",
      "Epoch 92, CIFAR-10 Batch 5:  loss:0.7333333492279053 accuracy:0.6993243098258972\n",
      "Epoch 93, CIFAR-10 Batch 1:  loss:0.7727259993553162 accuracy:0.7331081032752991\n",
      "Epoch 93, CIFAR-10 Batch 2:  loss:0.7493700981140137 accuracy:0.7195945978164673\n",
      "Epoch 93, CIFAR-10 Batch 3:  loss:0.6585954427719116 accuracy:0.7533783912658691\n",
      "Epoch 93, CIFAR-10 Batch 4:  loss:0.7169508934020996 accuracy:0.7533783912658691\n",
      "Epoch 93, CIFAR-10 Batch 5:  loss:0.7233328223228455 accuracy:0.7297297120094299\n",
      "Epoch 94, CIFAR-10 Batch 1:  loss:0.7516247034072876 accuracy:0.7297297120094299\n",
      "Epoch 94, CIFAR-10 Batch 2:  loss:0.7567914724349976 accuracy:0.7162162065505981\n",
      "Epoch 94, CIFAR-10 Batch 3:  loss:0.6415483951568604 accuracy:0.7668918967247009\n",
      "Epoch 94, CIFAR-10 Batch 4:  loss:0.7027013897895813 accuracy:0.7804054021835327\n",
      "Epoch 94, CIFAR-10 Batch 5:  loss:0.7242814898490906 accuracy:0.712837815284729\n",
      "Epoch 95, CIFAR-10 Batch 1:  loss:0.7452614903450012 accuracy:0.7297297120094299\n",
      "Epoch 95, CIFAR-10 Batch 2:  loss:0.7389495372772217 accuracy:0.7162162065505981\n",
      "Epoch 95, CIFAR-10 Batch 3:  loss:0.6621145009994507 accuracy:0.7702702879905701\n",
      "Epoch 95, CIFAR-10 Batch 4:  loss:0.7156926989555359 accuracy:0.7466216087341309\n",
      "Epoch 95, CIFAR-10 Batch 5:  loss:0.7006728649139404 accuracy:0.7331081032752991\n",
      "Epoch 96, CIFAR-10 Batch 1:  loss:0.7234234809875488 accuracy:0.7331081032752991\n",
      "Epoch 96, CIFAR-10 Batch 2:  loss:0.7183107137680054 accuracy:0.7162162065505981\n",
      "Epoch 96, CIFAR-10 Batch 3:  loss:0.6481319665908813 accuracy:0.7432432174682617\n",
      "Epoch 96, CIFAR-10 Batch 4:  loss:0.7059803009033203 accuracy:0.7736486196517944\n",
      "Epoch 96, CIFAR-10 Batch 5:  loss:0.6910009384155273 accuracy:0.7297297120094299\n",
      "Epoch 97, CIFAR-10 Batch 1:  loss:0.7228392362594604 accuracy:0.7364864945411682\n",
      "Epoch 97, CIFAR-10 Batch 2:  loss:0.7307338118553162 accuracy:0.7331081032752991\n",
      "Epoch 97, CIFAR-10 Batch 3:  loss:0.6368495225906372 accuracy:0.7635135054588318\n",
      "Epoch 97, CIFAR-10 Batch 4:  loss:0.6838676333427429 accuracy:0.787162184715271\n",
      "Epoch 97, CIFAR-10 Batch 5:  loss:0.702276885509491 accuracy:0.7432432174682617\n",
      "Epoch 98, CIFAR-10 Batch 1:  loss:0.7490436434745789 accuracy:0.7364864945411682\n",
      "Epoch 98, CIFAR-10 Batch 2:  loss:0.7422006726264954 accuracy:0.7195945978164673\n",
      "Epoch 98, CIFAR-10 Batch 3:  loss:0.6629706621170044 accuracy:0.7736486196517944\n",
      "Epoch 98, CIFAR-10 Batch 4:  loss:0.6813967227935791 accuracy:0.7601351141929626\n",
      "Epoch 98, CIFAR-10 Batch 5:  loss:0.6702057123184204 accuracy:0.7432432174682617\n",
      "Epoch 99, CIFAR-10 Batch 1:  loss:0.7145842909812927 accuracy:0.7567567825317383\n",
      "Epoch 99, CIFAR-10 Batch 2:  loss:0.7141107320785522 accuracy:0.7263513803482056\n",
      "Epoch 99, CIFAR-10 Batch 3:  loss:0.614082396030426 accuracy:0.7702702879905701\n",
      "Epoch 99, CIFAR-10 Batch 4:  loss:0.6830695271492004 accuracy:0.7837837934494019\n",
      "Epoch 99, CIFAR-10 Batch 5:  loss:0.6721351146697998 accuracy:0.7533783912658691\n",
      "Epoch 100, CIFAR-10 Batch 1:  loss:0.7106179594993591 accuracy:0.7466216087341309\n",
      "Epoch 100, CIFAR-10 Batch 2:  loss:0.7104283571243286 accuracy:0.7432432174682617\n",
      "Epoch 100, CIFAR-10 Batch 3:  loss:0.6145598888397217 accuracy:0.7905405163764954\n",
      "Epoch 100, CIFAR-10 Batch 4:  loss:0.684738278388977 accuracy:0.7668918967247009\n",
      "Epoch 100, CIFAR-10 Batch 5:  loss:0.6617920994758606 accuracy:0.7668918967247009\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.5708697140216827\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEigwbGIiIiISPD/rSxsQIZa2sYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a14d31400>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
